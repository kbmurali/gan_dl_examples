{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9652b9",
   "metadata": {
    "id": "cc9652b9",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "import tarfile\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4954840-ba56-4129-89f2-5df3c79f4824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arn8kahKBcay",
   "metadata": {
    "id": "arn8kahKBcay",
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "imgs_tar_url = 'https://github.com/kbmurali/hindi_hw_deep_gan/blob/main/hindi_alps.tar.gz?raw=true'\n",
    "\n",
    "tar_file = 'hindi_alps.tar.gz'\n",
    "\n",
    "urllib.request.urlretrieve( imgs_tar_url, tar_file )\n",
    "\n",
    "tar = tarfile.open( tar_file )\n",
    "\n",
    "# Extract all files to the current directory\n",
    "tar.extractall()\n",
    "\n",
    "# Close the tar file\n",
    "tar.close()\n",
    "'''\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b041e",
   "metadata": {
    "id": "be2b041e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mfGZenEcnepY",
   "metadata": {
    "id": "mfGZenEcnepY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=True)\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da683b8",
   "metadata": {
    "id": "3da683b8"
   },
   "outputs": [],
   "source": [
    "class HindiHWAlphabetGenerator( nn.Module ):\n",
    "    def __init__(self, input_channels=10, final_image_channels=1, conv_filter_factor=64 ):\n",
    "        super(HindiHWAlphabetGenerator, self).__init__()\n",
    "        \n",
    "        self.input_channels = input_channels\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        \n",
    "        ##Convolution layers\n",
    "        self.model.add_module( 'conv_1', self._convolution_layer( input_channels,\n",
    "                                                                  conv_filter_factor * 4, \n",
    "                                                                  kernel_size=3,\n",
    "                                                                  stride=2 ) )\n",
    "        \n",
    "        self.model.add_module( 'conv_2', self._convolution_layer( conv_filter_factor * 4,\n",
    "                                                                  conv_filter_factor * 8, \n",
    "                                                                  kernel_size=4,\n",
    "                                                                  stride=2 ) )\n",
    "        \n",
    "        self.model.add_module( 'conv_3', self._convolution_layer( conv_filter_factor * 8,\n",
    "                                                                  conv_filter_factor * 4, \n",
    "                                                                  kernel_size=4,\n",
    "                                                                  stride=1 ) )\n",
    "        \n",
    "        self.model.add_module( 'conv_4', self._convolution_layer( conv_filter_factor * 4,\n",
    "                                                                  conv_filter_factor * 2, \n",
    "                                                                  kernel_size=4,\n",
    "                                                                  stride=2 ) )\n",
    "        \n",
    "        self.model.add_module( 'conv_5', self._convolution_layer( conv_filter_factor * 2,\n",
    "                                                                  conv_filter_factor, \n",
    "                                                                  kernel_size=6,\n",
    "                                                                  stride=1 ) )\n",
    "        \n",
    "        ##Layer for image output\n",
    "        self.model.add_module( 'output', self._output_layer( conv_filter_factor ,\n",
    "                                                             final_image_channels,\n",
    "                                                             kernel_size=4,\n",
    "                                                             stride=1 ) )\n",
    "    \n",
    "    def forward( self, noise_tensors ):\n",
    "        '''\n",
    "        Given a input noise vectors, returns generated image for each noise vector.\n",
    "        Parameters:\n",
    "            noise_tensors: a noise tensor with dimensions (n_samples, input_channels)\n",
    "        '''\n",
    "        channelized_noise_inputs = self.channelize_noise_inputs( noise_tensors )\n",
    "        \n",
    "        return self.model( channelized_noise_inputs )\n",
    "    \n",
    "    def channelize_noise_inputs( self, noise_tensors ):\n",
    "        return noise_tensors.view( len(noise_tensors), self.input_channels, 1, 1)\n",
    "    \n",
    "    def _convolution_layer( self, input_channels, output_channels, kernel_size=4, stride=1 ):\n",
    "        return nn.Sequential(\n",
    "                                nn.ConvTranspose2d( input_channels,\n",
    "                                                    output_channels, \n",
    "                                                    kernel_size=kernel_size,\n",
    "                                                    stride=stride ),\n",
    "\n",
    "                                nn.BatchNorm2d( output_channels ),\n",
    "\n",
    "                                nn.ReLU(inplace=True)\n",
    "                            )\n",
    "    \n",
    "    def _output_layer( self, input_channels, output_channels, kernel_size=4, stride=1 ):\n",
    "        return nn.Sequential(\n",
    "                                nn.ConvTranspose2d( input_channels,\n",
    "                                                    output_channels, \n",
    "                                                    kernel_size=kernel_size,\n",
    "                                                    stride=stride ),\n",
    "\n",
    "                                nn.Tanh()\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l8bPzUMKkd6w",
   "metadata": {
    "id": "l8bPzUMKkd6w"
   },
   "outputs": [],
   "source": [
    "class HindiHWAlphabetDiscriminator( nn.Module ):\n",
    "    def __init__(self, image_dim=1024, hidden_dim=128, num_hidden=3 ):\n",
    "        super( HindiHWAlphabetDiscriminator, self ).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        \n",
    "        curr_input_dim = image_dim\n",
    "        \n",
    "        ##Hidden layers\n",
    "        for i in range(num_hidden-1, -1, -1 ):\n",
    "            hidden_out_dim = hidden_dim * (2 ** i)\n",
    "            \n",
    "            hidden_layer = self._hidden_layer( curr_input_dim, hidden_out_dim )\n",
    "            \n",
    "            self.model.add_module( 'hidden_' + str( num_hidden - i ), hidden_layer )\n",
    "            \n",
    "            curr_input_dim = hidden_out_dim\n",
    "        \n",
    "        ##Output layer for fake probability of the input image\n",
    "        self.model.add_module( 'output', nn.Linear( curr_input_dim, 1 ) )\n",
    "        \n",
    "    def forward( self, image_tensors ):\n",
    "        '''\n",
    "        Given a input image tensors, returns fake probability for each input image.\n",
    "        Parameters:\n",
    "            image_tensors: a tensor with dimensions (n_samples, img_dim)\n",
    "        '''\n",
    "\n",
    "        image_inputs = image_tensors.view( len(image_tensors), -1 )\n",
    "\n",
    "        return self.model( image_inputs )\n",
    "    \n",
    "    def _hidden_layer( self, input_dim, output_dim ):\n",
    "        '''\n",
    "        Parameters:\n",
    "            input_dim: a scalar dimension of the vector from the previous layer\n",
    "            output_dim: a scalar dimension of the vector output from this layer\n",
    "        Returns:\n",
    "            a NN hidden layer represented by a nn.Sequential instance containing\n",
    "            a Linear transformation followed by a LeakyReLU activation with a\n",
    "            negative slope of 0.2\n",
    "        '''\n",
    "        return nn.Sequential(\n",
    "            nn.Linear( input_dim, output_dim ),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0a133e",
   "metadata": {
    "id": "3c0a133e"
   },
   "outputs": [],
   "source": [
    "class GANTrainer:\n",
    "    def __init__( self,\n",
    "                  input_noise_dim,\n",
    "                  generator,\n",
    "                  discriminator,\n",
    "                  gen_optimizer,\n",
    "                  disc_optimizer,\n",
    "                  noise_inputs_generator_func,\n",
    "                  num_epochs,\n",
    "                  real_images_loader,\n",
    "                  criterion = nn.BCEWithLogitsLoss(),\n",
    "                  device='cpu',\n",
    "                  display_step=250 ):\n",
    "        self.input_noise_dim = input_noise_dim\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_optimizer = gen_optimizer\n",
    "        self.disc_optimizer = disc_optimizer\n",
    "        self.noise_inputs_generator_func = noise_inputs_generator_func\n",
    "        self.num_epochs = num_epochs\n",
    "        self.real_images_loader = real_images_loader\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.display_step = display_step\n",
    "    \n",
    "    @staticmethod\n",
    "    def plt_imgs( images_tensor, num_imgs=25, size=(1, 32, 32), nrow=5 ):\n",
    "        images_tensor = (images_tensor + 1) / 2\n",
    "        unflattened_imgs = images_tensor.detach().cpu()\n",
    "        img_quilt = make_grid( unflattened_imgs[:num_imgs], nrow=nrow )\n",
    "        plt.imshow( img_quilt.permute(1, 2, 0).squeeze() )\n",
    "        plt.show()\n",
    "    \n",
    "    def train( self ):\n",
    "        current_step = 1\n",
    "\n",
    "        mean_discriminator_loss = 0\n",
    "        mean_generator_loss = 0\n",
    "\n",
    "        for epoch in range( self.num_epochs ):\n",
    "            for _,(real_images, _) in enumerate( self.real_images_loader ):\n",
    "                cur_batch_size = len( real_images )\n",
    "                real_images = real_images.to( self.device )\n",
    "\n",
    "                discriminator_loss, generator_loss = self._train( real_images )\n",
    "\n",
    "                mean_discriminator_loss += discriminator_loss\n",
    "                mean_generator_loss += generator_loss\n",
    "\n",
    "                if current_step % self.display_step == 0:\n",
    "                    mean_discriminator_loss = mean_discriminator_loss/self.display_step\n",
    "                    mean_generator_loss = mean_generator_loss/self.display_step\n",
    "\n",
    "                    print(f\"Epoch {epoch}: Step {current_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "\n",
    "                    fake_gen_input_vectors = self.noise_inputs_generator_func( cur_batch_size,\n",
    "                                                                               self.input_noise_dim,\n",
    "                                                                               self.device )\n",
    "\n",
    "                    fake_images = self.generator( fake_gen_input_vectors )\n",
    "                    \n",
    "                    GANTrainer.plt_imgs( fake_images )\n",
    "                    #GANTrainer.plt_imgs( real_images )\n",
    "\n",
    "                    mean_discriminator_loss = 0\n",
    "                    mean_generator_loss = 0\n",
    "\n",
    "                current_step += 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        ret_str = str( self.__class__.__name__ ) + '(\\n' + \\\n",
    "                  '(generator): ' + self.generator.__str__() + \\\n",
    "                  '\\n(discriminator): ' + self.discriminator.__str__() + '\\n)'\n",
    "        \n",
    "        return ret_str\n",
    "    \n",
    "    def _discriminator_loss( self, real_images ):\n",
    "        '''\n",
    "        Parameters:\n",
    "            criterion: the loss function used to compare the discriminator's predictions \n",
    "                       to the ground truth of the images (fake = 0, real = 1)\n",
    "            real_images: a mini batch of real images\n",
    "        Returns:\n",
    "            discriminator_loss: a torch scalar loss value for the current batch\n",
    "        '''\n",
    "        input_noise_vectors = self.noise_inputs_generator_func( len( real_images ),\n",
    "                                                                self.input_noise_dim,\n",
    "                                                                self.device )\n",
    "\n",
    "        fake_images = self.generator( input_noise_vectors ).detach()\n",
    "\n",
    "        y_pred_fake = self.discriminator( fake_images )\n",
    "        y_expected_fake = torch.zeros_like( y_pred_fake )\n",
    "        fake_loss = self.criterion( y_pred_fake, y_expected_fake )\n",
    "\n",
    "        y_pred_real = self.discriminator( real_images )\n",
    "        y_expected_real = torch.ones_like( y_pred_real )\n",
    "        real_loss = self.criterion( y_pred_real, y_expected_real )\n",
    "\n",
    "        discriminator_loss = (fake_loss + real_loss) / 2\n",
    "\n",
    "        return discriminator_loss\n",
    "    \n",
    "    def _generator_loss( self, num_samples ):\n",
    "        '''\n",
    "        Parameters:\n",
    "            criterion: the loss function used to compare the discriminator's predictions \n",
    "                       to the ground truth reality of the images (fake = 1 in case of generator loss)\n",
    "            num_samples: the number of images the generator should produce\n",
    "        Returns:\n",
    "            generator_loss: a torch scalar loss value for the current batch\n",
    "        '''\n",
    "        input_noise_vectors = self.noise_inputs_generator_func( num_samples, self.input_noise_dim, self.device )\n",
    "\n",
    "        fake_images = self.generator( input_noise_vectors )\n",
    "\n",
    "        y_pred = self.discriminator( fake_images )\n",
    "        y_expected = torch.ones_like( y_pred )\n",
    "\n",
    "        generator_loss = self.criterion( y_pred, y_expected )\n",
    "\n",
    "        return generator_loss\n",
    "    \n",
    "    def _train( self, real_images ):\n",
    "        ### Update discriminator ###\n",
    "        # Zero out the gradients before backpropagation\n",
    "        self.disc_optimizer.zero_grad()\n",
    "\n",
    "        discriminator_loss = self._discriminator_loss( real_images )\n",
    "\n",
    "        # Update discriminator gradients\n",
    "        discriminator_loss.backward( retain_graph=True )\n",
    "\n",
    "        # Update discriminator optimizer\n",
    "        self.disc_optimizer.step()\n",
    "        \n",
    "        ### Update generator ###\n",
    "        self.gen_optimizer.zero_grad()\n",
    "        \n",
    "        num_samples = len( real_images )\n",
    "        \n",
    "        generator_loss = self._generator_loss( num_samples )\n",
    "        \n",
    "        generator_loss.backward( retain_graph=True )\n",
    "        \n",
    "        self.gen_optimizer.step()\n",
    "        \n",
    "        return discriminator_loss, generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c098c25",
   "metadata": {
    "id": "2c098c25"
   },
   "outputs": [],
   "source": [
    "def get_generator_inputs( num_samples, input_noise_dim, device='cpu'):\n",
    "        '''\n",
    "        Function to create a tensor of shape( num_samples, input_noise_dim ).\n",
    "        Each element tensor filled with random numbers from the normal distribution.\n",
    "        Parameters:\n",
    "            num_samples: a scalar for number of noise vectors to generate\n",
    "            input_noise_dim: a scalar representing the dimension of the noise vector\n",
    "            device: the device type\n",
    "        '''\n",
    "        return torch.randn( num_samples, input_noise_dim, device=device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03292958",
   "metadata": {
    "id": "03292958"
   },
   "outputs": [],
   "source": [
    "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "img_transformer = transforms.Compose([\n",
    "                        transforms.Resize(32),\n",
    "                        transforms.CenterCrop(32),\n",
    "                        transforms.Grayscale(),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5,), (0.5,))\n",
    "                    ])\n",
    "\n",
    "\n",
    "dataset = datasets.ImageFolder( 'alps/imgs', transform=img_transformer)\n",
    "\n",
    "real_images_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "num_epochs = 2\n",
    "display_step = 250\n",
    "input_noise_dim = 72\n",
    "\n",
    "gen = HindiHWAlphabetGenerator( input_channels=72, final_image_channels=1, conv_filter_factor=72 ).to( device )\n",
    "\n",
    "disc = HindiHWAlphabetDiscriminator( image_dim=1024, hidden_dim=320, num_hidden=4 ).to( device )\n",
    "\n",
    "# A learning rate of 0.0002 works well on DCGAN\n",
    "lr = 0.0002\n",
    "\n",
    "# These parameters control the optimizer's momentum\n",
    "# https://distill.pub/2017/momentum/\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "\n",
    "gen_optimizer = torch.optim.Adam( gen.parameters(), lr=lr,  betas=(beta_1, beta_2) )\n",
    "disc_optimizer = torch.optim.Adam( disc.parameters(), lr=lr,  betas=(beta_1, beta_2) )\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf029b",
   "metadata": {
    "id": "f9bf029b"
   },
   "outputs": [],
   "source": [
    "trainer = GANTrainer( input_noise_dim,\n",
    "                      gen,\n",
    "                      disc,\n",
    "                      gen_optimizer,\n",
    "                      disc_optimizer,\n",
    "                      get_generator_inputs,\n",
    "                      num_epochs,\n",
    "                      real_images_loader,\n",
    "                      criterion = criterion,\n",
    "                      device = device,\n",
    "                      display_step = display_step )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68087326",
   "metadata": {
    "id": "68087326"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "gpuType": "A100",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "premium",
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
